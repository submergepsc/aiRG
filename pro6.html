<!DOCTYPE html>
<html lang="zh-CN">
 <head>
  <meta charset="utf-8"/>
  <link href="https://blog.csdn.net/weixin_43378396/article/details/138572379" rel="canonical"/>
  <meta content="text/html; charset=utf-8" http-equiv="content-type"/>
  <meta content="webkit" name="renderer">
   <meta content="webkit" name="force-rendering">
    <meta content="IE=edge,chrome=1" http-equiv="X-UA-Compatible"/>
    <meta content="always" name="referrer"/>
    <meta content="no-siteapp" http-equiv="Cache-Control">
     <link href="#" media="handheld" rel="alternate"/>
     <meta content="pc" name="applicable-device"/>
     <link href="https://g.csdnimg.cn/static/logo/favicon32.ico" rel="shortcut icon" type="image/x-icon"/>
     <title>
      论文阅读：GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints-CSDN博客
     </title>
     <meta content="gqa: training generalized multi-query transformer models from multi-head che" name="keywords"/>
     <meta content='{"autorun":true,"install":true,"keyword":"gqa: training generalized multi-query transformer models from multi-head che"}' name="csdn-baidu-search"/>
     <meta content="文章浏览阅读1.9k次，点赞18次，收藏13次。语言模型的推理成本很高，这主要是由于加载 key 和 value 所带来的内存带宽开销。MQA 降低了这种开销，但代价是降低了模型的容量和质量。作者建议将 MHA 模型转换为 MQA 模型，只需原来预训练计算量的一小部分。此外，还引入了GQA，它是 MQA 和 MHA 的插值，能以与 MQA 相当的速度达到接近 MHA 的质量。_gqa: training generalized multi-query transformer models from multi-head che" name="description"/>
     <link href="https://csdnimg.cn/release/blogv2/dist/pc/css/detail_enter-2569705caf.min.css" rel="stylesheet" type="text/css"/>
     <link href="https://csdnimg.cn/release/blogv2/dist/pc/themesSkin/skin-growway/skin-growway-d937252ffc.min.css" rel="stylesheet" type="text/css"/>
     <meta content='{"type":"0","fixModel":"1"}' name="toolbar"/>
     <link href="https://csdnimg.cn/public/sandalstrap/1.4/css/sandalstrap.min.css" rel="stylesheet" type="text/css"/>
     <style>
      .MathJax, .MathJax_Message, .MathJax_Preview{
            display: none
        }
     </style>
    </meta>
   </meta>
  </meta>
  <style type="text/css">
   * { user-select: text; } pre{max-height: none!important; overflow-y: hidden;}
  </style>
 </head>
 <body class="nodata" style="">
  <link href="https://csdnimg.cn/release/blogv2/dist/pc/css/blog_code-01256533b5.min.css" rel="stylesheet"/>
  <link href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/chart-3456820cac.css" rel="stylesheet">
   <link href="https://g.csdnimg.cn/lib/swiper/6.0.4/css/swiper.css" rel="stylesheet">
    <div class="main_father clearfix d-flex justify-content-center mainfather-concision" style="height:100%;">
     <div class="container clearfix container-concision" id="mainBox">
      <main>
       <div class="blog-content-box">
        <div class="article-header-box" id="article-header-box">
         <div class="article-header">
          <div class="article-title-box">
           <h1 class="title-article" id="articleContentId">
            论文阅读：GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints
           </h1>
          </div>
          <div class="article-info-box">
           <div class="article-bar-top">
            <div class="bar-content active">
             <span class="article-type-text original">
              原创
             </span>
             <a class="article-vip-box" data-report-click='{"spm":"3001.10404"}' data-report-query="spm=3001.10404" data-report-view='{"spm":"3001.10404"}' href="https://mall.csdn.net/vip" target="_blank">
              <img alt="" class="article-vip-img-new" src="https://csdnimg.cn/release/blogv2/dist/pc/img/identityVipNew.png"/>
             </a>
             <span class="time">
              已于 2024-05-08 18:53:34 修改
             </span>
             <span class="border-dian">
              ·
             </span>
             <span class="read-count">
              1.9k 阅读
             </span>
             <div class="read-count-box is-like like-ab-new" data-type="top">
              <span class="border-dian">
               ·
              </span>
              <img alt="" class="article-read-img article-heard-img active" id="is-like-imgactive-new" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newHeart2023Active.png" style="display:none"/>
              <img alt="" class="article-read-img article-heard-img" id="is-like-img-new" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newHeart2023Black.png" style="display:block"/>
              <span class="read-count" id="blog-digg-num" style="color:;">
               18
              </span>
             </div>
             <span class="border-dian">
              ·
             </span>
             <a class="un-collection" data-report-click='{"mod":"popu_823","spm":"1001.2101.3001.4232","ab":"new"}' id="blog_detail_zk_collection">
              <img alt="" class="article-collect-img article-heard-img un-collect-status isdefault" src="https://csdnimg.cn/release/blogv2/dist/pc/img/tobarCollect2.png" style="display:inline-block"/>
              <img alt="" class="article-collect-img article-heard-img collect-status isactive" src="https://csdnimg.cn/release/blogv2/dist/pc/img/tobarCollectionActive2.png" style="display:none"/>
              <span class="get-collection">
               13
              </span>
             </a>
             <span class="border-dian">
              ·
             </span>
             <div class="href-article-edit-new">
              <span class="href-article-edit-click">
               CC 4.0 BY-SA版权
              </span>
              <div class="slide-content-box-new">
               版权声明：本文为博主原创文章，遵循
               <a href="http://creativecommons.org/licenses/by-sa/4.0/" rel="noopener" target="_blank">
                CC 4.0 BY-SA
               </a>
               版权协议，转载请附上原文出处链接和本声明。
              </div>
             </div>
            </div>
            <div class="operating active">
            </div>
           </div>
           <div class="blog-tags-box">
            <div class="tags-box artic-tag-box">
             <div class="article-tag">
              <span class="label">
               文章标签：
              </span>
              <p>
               <a class="tag-link-new" data-report-click='{"mod":"popu_626","spm":"1001.2101.3001.4223","strategy":"论文阅读","ab":"new","extra":"{\"searchword\":\"论文阅读\"}"}' data-report-query="spm=1001.2101.3001.4223" data-report-view='{"mod":"popu_626","spm":"1001.2101.3001.4223","strategy":"论文阅读","ab":"new","extra":"{\"searchword\":\"论文阅读\"}"}' href="https://so.csdn.net/so/search/s.do?q=%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB&amp;t=all&amp;o=vip&amp;s=&amp;l=&amp;f=&amp;viparticle=&amp;from_tracking_code=tag_word&amp;from_code=app_blog_art" rel="noopener" target="_blank">
                #论文阅读
               </a>
               <a class="tag-link-new" data-report-click='{"mod":"popu_626","spm":"1001.2101.3001.4223","strategy":"论文笔记","ab":"new","extra":"{\"searchword\":\"论文笔记\"}"}' data-report-query="spm=1001.2101.3001.4223" data-report-view='{"mod":"popu_626","spm":"1001.2101.3001.4223","strategy":"论文笔记","ab":"new","extra":"{\"searchword\":\"论文笔记\"}"}' href="https://so.csdn.net/so/search/s.do?q=%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0&amp;t=all&amp;o=vip&amp;s=&amp;l=&amp;f=&amp;viparticle=&amp;from_tracking_code=tag_word&amp;from_code=app_blog_art" rel="noopener" target="_blank">
                #论文笔记
               </a>
               <a class="tag-link-new" data-report-click='{"mod":"popu_626","spm":"1001.2101.3001.4223","strategy":"人工智能","ab":"new","extra":"{\"searchword\":\"人工智能\"}"}' data-report-query="spm=1001.2101.3001.4223" data-report-view='{"mod":"popu_626","spm":"1001.2101.3001.4223","strategy":"人工智能","ab":"new","extra":"{\"searchword\":\"人工智能\"}"}' href="https://so.csdn.net/so/search/s.do?q=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD&amp;t=all&amp;o=vip&amp;s=&amp;l=&amp;f=&amp;viparticle=&amp;from_tracking_code=tag_word&amp;from_code=app_blog_art" rel="noopener" target="_blank">
                #人工智能
               </a>
               <a class="tag-link-new" data-report-click='{"mod":"popu_626","spm":"1001.2101.3001.4223","strategy":"自然语言处理","ab":"new","extra":"{\"searchword\":\"自然语言处理\"}"}' data-report-query="spm=1001.2101.3001.4223" data-report-view='{"mod":"popu_626","spm":"1001.2101.3001.4223","strategy":"自然语言处理","ab":"new","extra":"{\"searchword\":\"自然语言处理\"}"}' href="https://so.csdn.net/so/search/s.do?q=%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86&amp;t=all&amp;o=vip&amp;s=&amp;l=&amp;f=&amp;viparticle=&amp;from_tracking_code=tag_word&amp;from_code=app_blog_art" rel="noopener" target="_blank">
                #自然语言处理
               </a>
              </p>
             </div>
             <p class="community-name" id="community-name">
             </p>
            </div>
           </div>
           <div class="up-time">
            <span>
             于 2024-05-08 18:46:50 首次发布
            </span>
           </div>
          </div>
         </div>
        </div>
        <div class="active-padding" id="blogHuaweiyunAdvert">
        </div>
        <article class="baidu_pl">
         <div class="article_content clearfix" id="article_content">
          <link href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/kdoc_html_views-1a98987dfd.css" rel="stylesheet"/>
          <link href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/ck_htmledit_views-10bf609291.css" rel="stylesheet"/>
          <div class="markdown_views prism-atom-one-light" id="content_views">
           <svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
           </svg>
           <p>
            自回归解码器推理是 Transformer 模型的一个严重瓶颈，虽然现在的大模型（LLM）会通过 kv cache 存储历史 kv 信息，避免每个解码步骤重复计算，但这需要额外的内存空间，并且加大了内存带宽的开销（需要将 kv cache 从显存中加载到 GPU 的 SP）。因此，在 decoder-only 模型的推理过程中，pre-fill 阶段是 compute-bound，瓶颈在于 GPU 的计算，需要将输入的 prompt 计算 kv 信息；decode 阶段则是 memory-bound，瓶颈在于加载 kv cache，并且随着 context 的增加，解码的速度越慢。
           </p>
           <p>
            因此，就有研究人员考虑是否可以不再是一个 query 头对应一个 key 和 value 头的 multi-head attention？于是提出了 MQA，多个 query 对应一个 key 和 value 头。我们知道 self-attention 中的主要参数权重是 Q、K、V 和 O 这四个矩阵，其中 K 和 V 的头从原先的 32（Llama3-8B）减少至 1 后，可以减少训练所需的参数量以及推理时加载的 kv cache，这对于模型训练亦或是推理都能节省大量的时间与成本。
           </p>
           <p>
            但直接将 key 和 value 的头从 32 减少至 1，不可避免会损失信息（类似于降维），从而影响模型的性能。本篇论文在附录 A 的训练稳定性中也讲述了 MQA 预训练时的不稳定：
           </p>
           <blockquote>
            <p>
             作者发现，MQA 会导致训练不稳定，尤其是与长输入任务相结合时。作者从头开始用 MQA 训练了多个 T5-Large 模型。在每种情况下，预训练都会出现频繁的损失峰值，最终模型在长输入任务中会立即出现偏差。因此，对于不稳定任务上的 multi-query 模型，报告的是多次运行的平均性能。不过，经过 up-training 的 GQA 模型似乎比较稳定。
            </p>
           </blockquote>
           <p>
            我们能否将 MHA（一对一）和 MQA（all 对 1）取个折中呢？既能不损失过多的信息，同时还能减少 key 和 value 的头数？一个朴素的想法是多（query）对一（key 和 value），这就是本篇论文提出的 GQA，多组查询注意力。
           </p>
           <h2>
            <a id="GQA_10">
            </a>
            分组查询注意力（GQA）
           </h2>
           <p>
            GQA 将 query 头分为 G 组，每组共享一个 key 和 value 头。GQA-G 指的是有 G 个组的分组 query。
           </p>
           <ul>
            <li>
             GQA-1 只有一个组，因此也只有 1 个 key和 value 头，相当于 MQA；
            </li>
            <li>
             GQA-H 的组数等于 query 头数，相当于 MHA。
            </li>
           </ul>
           <p>
            <img alt="" src="https://i-blog.csdnimg.cn/blog_migrate/b438b5cc4d7f90e26377be9a96b6ff92.png"/>
           </p>
           <blockquote>
            <p>
             图 2：GQA 方法概述。MHA 有 H 个 query、key 和 value 头。MQA 在所有 query 头中共享单个 key 和 value 头。GQA 则是为每组 query 头共享单个 key 和 value 头，介于 MHA 和 MQA 之间。
            </p>
           </blockquote>
           <p>
            图 2 显示了分组查询注意力和多头/多查询注意力的比较。从 MHA 到 MQA，可以将 H 个 kv 头减少到单个 kv 头，从而将 kv cache 的大小以及需要加载的数据量减少 H 倍，但模型训练的稳定性以及效果会有所下降。GQA 的 kv 分组会让模型的质量比 MQA 高，速度比 MHA 快，这是一种有利的权衡。
           </p>
           <p>
            较大的模型通常会按比例增加头的数量，MQA 对此不敏感（无论 query 头怎么增加，key 和 value 头永远是 1）代表了对内存带宽和容量的更大削减。GQA 可以在模型规模增大时，保持相同比例的带宽和容量缩减，这能为大模型提供特别好的权衡（PS：Llama2 只有 70B 模型是 GQA，而 Llama3 已经全部使用 GQA）。
           </p>
           <h2>
            <a id="Uptraining_22">
            </a>
            Uptraining
           </h2>
           <p>
            从 MHA 模型转换到 MQA 模型分为两个步骤：首先是转换检查点，其次是额外的预训练，以使模型适应新的结构。图 1 显示了将 MHA 检查点转换为 MQA 检查点的过程。
            <br/>
            <img alt="" src="https://i-blog.csdnimg.cn/blog_migrate/74fd2379ea424b4ed979c3e3540d95fc.png"/>
           </p>
           <blockquote>
            <p>
             图 1：从 multi-head 转换为 multi-query 注意力的概述。来自所有 head 的 key 和 value 投影矩阵被平均池化到一个 head。
            </p>
           </blockquote>
           <p>
            在将 multi-head checkpoint 转换为 MQA checkpoint 时，将 multi-head kv 头的投影矩阵平均池化成单个头的投影矩阵，作者发现这比选择单个 kv 头（从已有的 multi-head 中选择）或从头开始随机初始化新的 kv 头效果更好。然后，在相同的预训练配方上，对转换后的 checkpoint 进行原始训练步骤的一小部分 α 的预训练。通过持续预训练（continual pretrain）来让模型在原始的一小部分预训练数据集上适应新的结构。context 扩展也是相同的做法，我们往往会基于已开源的预训练模型，例如 llama、mistral 等 base model 上做持续预训练，通过 NTK-aware RoPE 等手段调整模型支持的最大上下文长度。为了让模型更好地适应调整后的 context length，我们会继续预训练或者 SFT 来让模型适应。当你扩展新的知识时，最好是用实践来验证下理论，模型同样也是如此。
           </p>
           <p>
            上文讲述了从 MHA 转换为 MQA，同理可得，在将 MHA checkpoint 转换为 GQA checkpoint 时，通过平均池化该组中的所有 kv 头来构建每个组的 kv 头。
           </p>
           <h2>
            <a id="_30">
            </a>
            实验部分
           </h2>
           <h3>
            <a id="_31">
            </a>
            主要结果
           </h3>
           <p>
            图 3 显示了 MHA T5-Large 和 T5-XXL 模型以及上训练比例为 α = 0.05 的 MQA 和 GQA-8 XXL 模型在所有数据集上的平均性能与平均推理时间的函数关系。
            <br/>
            <img alt="" src="https://i-blog.csdnimg.cn/blog_migrate/c9d9f92888b860d569733d511f2122ba.png"/>
           </p>
           <blockquote>
            <p>
             图 3：经过 up-training 的 MQA 和 MHA 相比具有更高的质量和更快的速度，与 MHA-Large 相比具有更好的折衷效果，而 GQA 则具有更好的性能，速度提升与 MQA-XXL 相似，质量与 MHA-XXL 相当。
            </p>
           </blockquote>
           <p>
            作者发现，与 MHA 模型相比，较大的 up-training MQA 模型提供了有利的权衡，与 MHA-Large 相比，它的质量更高，推理速度更快。此外，GQA 还能显著提高质量，性能接近 MHA-XXL，速度接近 MQA。表 1 包含了所有数据集的全部结果。
           </p>
           <p>
            <img alt="" src="https://i-blog.csdnimg.cn/blog_migrate/990071993ac685a1210d62556983005b.png"/>
           </p>
           <blockquote>
            <p>
             表 1：在摘要数据集 CNN/Daily Mail、arXiv、PubMed、MediaSum 和 MultiNews、翻译数据集 WMT 以及答题数据集 TriviaQA 上，使用 MHA 的 T5 Large 模型和 XXL 模型，以及使用 MQA 和 GQA 的 5% 的 up-training 的 T5-XXL 模型的推理时间和平均验证集性能比较。
            </p>
           </blockquote>
           <h3>
            <a id="checkpoint__41">
            </a>
            checkpoint 转换实验
           </h3>
           <p>
            <img alt="" src="https://i-blog.csdnimg.cn/blog_migrate/14be5f4203c0c199847eb9875021d57c.png"/>
           </p>
           <blockquote>
            <p>
             图 4：在α = 0.05 的情况下，不同 checkpoint 转换方法对 T5-Large uptrain 到 MQA 的性能比较。Mean mean-pools 分配 key 和value 头；First 选择第一个 head；Random 初始化所有 heads。
            </p>
           </blockquote>
           <p>
            图 4 比较了不同 checkpoint 转换方法的性能。mean pooling 似乎效果最好，其次是选择单个 head，最后是随机初始化。直观地说，结果是根据预训练模型信息的保留程度排序的。
           </p>
           <h2>
            <a id="_46">
            </a>
            总结
           </h2>
           <p>
            语言模型的推理成本很高，这主要是由于加载 key 和 value 所带来的内存带宽开销。MQA 降低了这种开销，但代价是降低了模型的容量和质量。作者建议将 MHA 模型转换为 MQA 模型，只需原来预训练计算量的一小部分。此外，还引入了
            <strong>
             GQA，它是 MQA 和 MHA 的插值，能以与 MQA 相当的速度达到接近 MHA 的质量
            </strong>
            。
           </p>
           <h2>
            <a id="QA__50">
            </a>
            QA 相关
           </h2>
           <p>
            论文中提到 GQA 可以加速推理，那么到底加速了哪一部分呢？
           </p>
           <ul>
            <li>
             <p>
              <strong>
               训练阶段
              </strong>
              ：GQA 可以减少 self-attention 块的参数量，减少训练的参数量，从而加快训练。例如，MHA 的 self-attention 块需要训练
              <span class="katex--inline">
               <span class="katex">
                <span class="katex-mathml">
                 WQW_Q
                </span>
                <span class="katex-html">
                 <span class="base">
                  <span class="strut" style="height: 0.9694em; vertical-align: -0.2861em;">
                  </span>
                  <span class="mord">
                   <span class="mord mathnormal" style="margin-right: 0.1389em;">
                    W
                   </span>
                   <span class="msupsub">
                    <span class="vlist-t vlist-t2">
                     <span class="vlist-r">
                      <span class="vlist" style="height: 0.3283em;">
                       <span class="" style="top: -2.55em; margin-left: -0.1389em; margin-right: 0.05em;">
                        <span class="pstrut" style="height: 2.7em;">
                        </span>
                        <span class="sizing reset-size6 size3 mtight">
                         <span class="mord mathnormal mtight">
                          Q
                         </span>
                        </span>
                       </span>
                      </span>
                      <span class="vlist-s">
                       ​
                      </span>
                     </span>
                     <span class="vlist-r">
                      <span class="vlist" style="height: 0.2861em;">
                       <span class="">
                       </span>
                      </span>
                     </span>
                    </span>
                   </span>
                  </span>
                 </span>
                </span>
               </span>
              </span>
              、
              <span class="katex--inline">
               <span class="katex">
                <span class="katex-mathml">
                 WKW_K
                </span>
                <span class="katex-html">
                 <span class="base">
                  <span class="strut" style="height: 0.8333em; vertical-align: -0.15em;">
                  </span>
                  <span class="mord">
                   <span class="mord mathnormal" style="margin-right: 0.1389em;">
                    W
                   </span>
                   <span class="msupsub">
                    <span class="vlist-t vlist-t2">
                     <span class="vlist-r">
                      <span class="vlist" style="height: 0.3283em;">
                       <span class="" style="top: -2.55em; margin-left: -0.1389em; margin-right: 0.05em;">
                        <span class="pstrut" style="height: 2.7em;">
                        </span>
                        <span class="sizing reset-size6 size3 mtight">
                         <span class="mord mathnormal mtight" style="margin-right: 0.0715em;">
                          K
                         </span>
                        </span>
                       </span>
                      </span>
                      <span class="vlist-s">
                       ​
                      </span>
                     </span>
                     <span class="vlist-r">
                      <span class="vlist" style="height: 0.15em;">
                       <span class="">
                       </span>
                      </span>
                     </span>
                    </span>
                   </span>
                  </span>
                 </span>
                </span>
               </span>
              </span>
              、
              <span class="katex--inline">
               <span class="katex">
                <span class="katex-mathml">
                 WVW_V
                </span>
                <span class="katex-html">
                 <span class="base">
                  <span class="strut" style="height: 0.8333em; vertical-align: -0.15em;">
                  </span>
                  <span class="mord">
                   <span class="mord mathnormal" style="margin-right: 0.1389em;">
                    W
                   </span>
                   <span class="msupsub">
                    <span class="vlist-t vlist-t2">
                     <span class="vlist-r">
                      <span class="vlist" style="height: 0.3283em;">
                       <span class="" style="top: -2.55em; margin-left: -0.1389em; margin-right: 0.05em;">
                        <span class="pstrut" style="height: 2.7em;">
                        </span>
                        <span class="sizing reset-size6 size3 mtight">
                         <span class="mord mathnormal mtight" style="margin-right: 0.2222em;">
                          V
                         </span>
                        </span>
                       </span>
                      </span>
                      <span class="vlist-s">
                       ​
                      </span>
                     </span>
                     <span class="vlist-r">
                      <span class="vlist" style="height: 0.15em;">
                       <span class="">
                       </span>
                      </span>
                     </span>
                    </span>
                   </span>
                  </span>
                 </span>
                </span>
               </span>
              </span>
              和
              <span class="katex--inline">
               <span class="katex">
                <span class="katex-mathml">
                 WOW_O
                </span>
                <span class="katex-html">
                 <span class="base">
                  <span class="strut" style="height: 0.8333em; vertical-align: -0.15em;">
                  </span>
                  <span class="mord">
                   <span class="mord mathnormal" style="margin-right: 0.1389em;">
                    W
                   </span>
                   <span class="msupsub">
                    <span class="vlist-t vlist-t2">
                     <span class="vlist-r">
                      <span class="vlist" style="height: 0.3283em;">
                       <span class="" style="top: -2.55em; margin-left: -0.1389em; margin-right: 0.05em;">
                        <span class="pstrut" style="height: 2.7em;">
                        </span>
                        <span class="sizing reset-size6 size3 mtight">
                         <span class="mord mathnormal mtight" style="margin-right: 0.0278em;">
                          O
                         </span>
                        </span>
                       </span>
                      </span>
                      <span class="vlist-s">
                       ​
                      </span>
                     </span>
                     <span class="vlist-r">
                      <span class="vlist" style="height: 0.15em;">
                       <span class="">
                       </span>
                      </span>
                     </span>
                    </span>
                   </span>
                  </span>
                 </span>
                </span>
               </span>
              </span>
              ，这 4 个权重矩阵的形状为 [h, h]，因此总参数量为
              <span class="katex--inline">
               <span class="katex">
                <span class="katex-mathml">
                 4h2+4h4h^2 + 4h
                </span>
                <span class="katex-html">
                 <span class="base">
                  <span class="strut" style="height: 0.8974em; vertical-align: -0.0833em;">
                  </span>
                  <span class="mord">
                   4
                  </span>
                  <span class="mord">
                   <span class="mord mathnormal">
                    h
                   </span>
                   <span class="msupsub">
                    <span class="vlist-t">
                     <span class="vlist-r">
                      <span class="vlist" style="height: 0.8141em;">
                       <span class="" style="top: -3.063em; margin-right: 0.05em;">
                        <span class="pstrut" style="height: 2.7em;">
                        </span>
                        <span class="sizing reset-size6 size3 mtight">
                         <span class="mord mtight">
                          2
                         </span>
                        </span>
                       </span>
                      </span>
                     </span>
                    </span>
                   </span>
                  </span>
                  <span class="mspace" style="margin-right: 0.2222em;">
                  </span>
                  <span class="mbin">
                   +
                  </span>
                  <span class="mspace" style="margin-right: 0.2222em;">
                  </span>
                 </span>
                 <span class="base">
                  <span class="strut" style="height: 0.6944em;">
                  </span>
                  <span class="mord">
                   4
                  </span>
                  <span class="mord mathnormal">
                   h
                  </span>
                 </span>
                </span>
               </span>
              </span>
              。使用 GQA 后，K 和 V 的注意力头数会减少，例如为原先的 h/8，那么总参数量就变为
              <span class="katex--inline">
               <span class="katex">
                <span class="katex-mathml">
                 94h2+94h\frac{9}{4}h^2 + \frac{9}{4}h
                </span>
                <span class="katex-html">
                 <span class="base">
                  <span class="strut" style="height: 1.1901em; vertical-align: -0.345em;">
                  </span>
                  <span class="mord">
                   <span class="mopen nulldelimiter">
                   </span>
                   <span class="mfrac">
                    <span class="vlist-t vlist-t2">
                     <span class="vlist-r">
                      <span class="vlist" style="height: 0.8451em;">
                       <span class="" style="top: -2.655em;">
                        <span class="pstrut" style="height: 3em;">
                        </span>
                        <span class="sizing reset-size6 size3 mtight">
                         <span class="mord mtight">
                          <span class="mord mtight">
                           4
                          </span>
                         </span>
                        </span>
                       </span>
                       <span class="" style="top: -3.23em;">
                        <span class="pstrut" style="height: 3em;">
                        </span>
                        <span class="frac-line" style="border-bottom-width: 0.04em;">
                        </span>
                       </span>
                       <span class="" style="top: -3.394em;">
                        <span class="pstrut" style="height: 3em;">
                        </span>
                        <span class="sizing reset-size6 size3 mtight">
                         <span class="mord mtight">
                          <span class="mord mtight">
                           9
                          </span>
                         </span>
                        </span>
                       </span>
                      </span>
                      <span class="vlist-s">
                       ​
                      </span>
                     </span>
                     <span class="vlist-r">
                      <span class="vlist" style="height: 0.345em;">
                       <span class="">
                       </span>
                      </span>
                     </span>
                    </span>
                   </span>
                   <span class="mclose nulldelimiter">
                   </span>
                  </span>
                  <span class="mord">
                   <span class="mord mathnormal">
                    h
                   </span>
                   <span class="msupsub">
                    <span class="vlist-t">
                     <span class="vlist-r">
                      <span class="vlist" style="height: 0.8141em;">
                       <span class="" style="top: -3.063em; margin-right: 0.05em;">
                        <span class="pstrut" style="height: 2.7em;">
                        </span>
                        <span class="sizing reset-size6 size3 mtight">
                         <span class="mord mtight">
                          2
                         </span>
                        </span>
                       </span>
                      </span>
                     </span>
                    </span>
                   </span>
                  </span>
                  <span class="mspace" style="margin-right: 0.2222em;">
                  </span>
                  <span class="mbin">
                   +
                  </span>
                  <span class="mspace" style="margin-right: 0.2222em;">
                  </span>
                 </span>
                 <span class="base">
                  <span class="strut" style="height: 1.1901em; vertical-align: -0.345em;">
                  </span>
                  <span class="mord">
                   <span class="mopen nulldelimiter">
                   </span>
                   <span class="mfrac">
                    <span class="vlist-t vlist-t2">
                     <span class="vlist-r">
                      <span class="vlist" style="height: 0.8451em;">
                       <span class="" style="top: -2.655em;">
                        <span class="pstrut" style="height: 3em;">
                        </span>
                        <span class="sizing reset-size6 size3 mtight">
                         <span class="mord mtight">
                          <span class="mord mtight">
                           4
                          </span>
                         </span>
                        </span>
                       </span>
                       <span class="" style="top: -3.23em;">
                        <span class="pstrut" style="height: 3em;">
                        </span>
                        <span class="frac-line" style="border-bottom-width: 0.04em;">
                        </span>
                       </span>
                       <span class="" style="top: -3.394em;">
                        <span class="pstrut" style="height: 3em;">
                        </span>
                        <span class="sizing reset-size6 size3 mtight">
                         <span class="mord mtight">
                          <span class="mord mtight">
                           9
                          </span>
                         </span>
                        </span>
                       </span>
                      </span>
                      <span class="vlist-s">
                       ​
                      </span>
                     </span>
                     <span class="vlist-r">
                      <span class="vlist" style="height: 0.345em;">
                       <span class="">
                       </span>
                      </span>
                     </span>
                    </span>
                   </span>
                   <span class="mclose nulldelimiter">
                   </span>
                  </span>
                  <span class="mord mathnormal">
                   h
                  </span>
                 </span>
                </span>
               </span>
              </span>
              。
             </p>
             <blockquote>
              <p>
               <strong>
                猜测
               </strong>
               ：Llama2-70B 中采用 GQA，我理解是为了减少参数量，加快训练速度，同时 GQA 并不会减少太多的性能，尤其对于 70B 模型来说，这点性能损失与模型规模相比完全可以不用考虑，训练速度更为重要。
              </p>
             </blockquote>
            </li>
            <li>
             <p>
              <strong>
               推理阶段
              </strong>
              ：
              <span class="katex--inline">
               <span class="katex">
                <span class="katex-mathml">
                 WKW_K
                </span>
                <span class="katex-html">
                 <span class="base">
                  <span class="strut" style="height: 0.8333em; vertical-align: -0.15em;">
                  </span>
                  <span class="mord">
                   <span class="mord mathnormal" style="margin-right: 0.1389em;">
                    W
                   </span>
                   <span class="msupsub">
                    <span class="vlist-t vlist-t2">
                     <span class="vlist-r">
                      <span class="vlist" style="height: 0.3283em;">
                       <span class="" style="top: -2.55em; margin-left: -0.1389em; margin-right: 0.05em;">
                        <span class="pstrut" style="height: 2.7em;">
                        </span>
                        <span class="sizing reset-size6 size3 mtight">
                         <span class="mord mathnormal mtight" style="margin-right: 0.0715em;">
                          K
                         </span>
                        </span>
                       </span>
                      </span>
                      <span class="vlist-s">
                       ​
                      </span>
                     </span>
                     <span class="vlist-r">
                      <span class="vlist" style="height: 0.15em;">
                       <span class="">
                       </span>
                      </span>
                     </span>
                    </span>
                   </span>
                  </span>
                 </span>
                </span>
               </span>
              </span>
              和
              <span class="katex--inline">
               <span class="katex">
                <span class="katex-mathml">
                 WVW_V
                </span>
                <span class="katex-html">
                 <span class="base">
                  <span class="strut" style="height: 0.8333em; vertical-align: -0.15em;">
                  </span>
                  <span class="mord">
                   <span class="mord mathnormal" style="margin-right: 0.1389em;">
                    W
                   </span>
                   <span class="msupsub">
                    <span class="vlist-t vlist-t2">
                     <span class="vlist-r">
                      <span class="vlist" style="height: 0.3283em;">
                       <span class="" style="top: -2.55em; margin-left: -0.1389em; margin-right: 0.05em;">
                        <span class="pstrut" style="height: 2.7em;">
                        </span>
                        <span class="sizing reset-size6 size3 mtight">
                         <span class="mord mathnormal mtight" style="margin-right: 0.2222em;">
                          V
                         </span>
                        </span>
                       </span>
                      </span>
                      <span class="vlist-s">
                       ​
                      </span>
                     </span>
                     <span class="vlist-r">
                      <span class="vlist" style="height: 0.15em;">
                       <span class="">
                       </span>
                      </span>
                     </span>
                    </span>
                   </span>
                  </span>
                 </span>
                </span>
               </span>
              </span>
              的参数量较少，但为了和 Q 有相同的形状来进行矩阵乘法，会调用
              <code>
               repeat_kv
              </code>
              函数拷贝至与 Q 相同的形状，也就是说
              <span class="katex--inline">
               <span class="katex">
                <span class="katex-mathml">
                 QKTQK^T
                </span>
                <span class="katex-html">
                 <span class="base">
                  <span class="strut" style="height: 1.0358em; vertical-align: -0.1944em;">
                  </span>
                  <span class="mord mathnormal">
                   Q
                  </span>
                  <span class="mord">
                   <span class="mord mathnormal" style="margin-right: 0.0715em;">
                    K
                   </span>
                   <span class="msupsub">
                    <span class="vlist-t">
                     <span class="vlist-r">
                      <span class="vlist" style="height: 0.8413em;">
                       <span class="" style="top: -3.063em; margin-right: 0.05em;">
                        <span class="pstrut" style="height: 2.7em;">
                        </span>
                        <span class="sizing reset-size6 size3 mtight">
                         <span class="mord mathnormal mtight" style="margin-right: 0.1389em;">
                          T
                         </span>
                        </span>
                       </span>
                      </span>
                     </span>
                    </span>
                   </span>
                  </span>
                 </span>
                </span>
               </span>
              </span>
              的计算与 MHA 没有变化。区别就是在计算
              <code>
               key_states
              </code>
              和
              <code>
               value_states
              </code>
              时的维度较少以及新增了拷贝的操作。
             </p>
             <pre><code class="prism language-Python">query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)
key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)
value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)

past_key_value = getattr(self, "past_key_value", past_key_value)
cos, sin = self.rotary_emb(value_states, position_ids)
query_states, key_states = apply_rotary_pos_emb(query_states, key_states, cos, sin)

key_states = repeat_kv(key_states, self.num_key_value_groups)
value_states = repeat_kv(value_states, self.num_key_value_groups)
</code></pre>
             <p>
              GQA 真正起到推理加速的作用是：
             </p>
             <ul>
              <li>
               <strong>
                减少了从显存（HBM 或 SRAM）中读取的 kv cache 数据量
               </strong>
               ：缓解 memory-bound（计算单元处理的速度快于内存单元，可以理解为传送带的速度比较慢，而车间加工的速度非常快，车间工人们忙完手中的活后，需要等传输带的原材料到才能继续工作），减少计算单元等待的时间，提高了计算利用率。
              </li>
              <li>
               <strong>
                减少了参数量以及 kv cache 占用的显存
               </strong>
               ：空出来的显存用来增加 LLM serving 的 batch size，从而增加服务的总吞吐量。
              </li>
             </ul>
            </li>
           </ul>
           <p>
            当 context 较短时，例如输入长度 + 输出长度 = 3500 + 500 = 4k，且模型规模较小，例如 Llama2-7B，当 batch size = 1，float16 数据格式存储，其 kv cache 总显存占用
            <span class="katex--inline">
             <span class="katex">
              <span class="katex-mathml">
               4bshl=4×1×4000×4096×32=2,097,152,000≈1.95GB4bshl = 4 \times 1 \times 4000 \times 4096 \times 32 = 2,097,152,000 \approx 1.95GB
              </span>
              <span class="katex-html">
               <span class="base">
                <span class="strut" style="height: 0.6944em;">
                </span>
                <span class="mord">
                 4
                </span>
                <span class="mord mathnormal">
                 b
                </span>
                <span class="mord mathnormal">
                 s
                </span>
                <span class="mord mathnormal">
                 h
                </span>
                <span class="mord mathnormal" style="margin-right: 0.0197em;">
                 l
                </span>
                <span class="mspace" style="margin-right: 0.2778em;">
                </span>
                <span class="mrel">
                 =
                </span>
                <span class="mspace" style="margin-right: 0.2778em;">
                </span>
               </span>
               <span class="base">
                <span class="strut" style="height: 0.7278em; vertical-align: -0.0833em;">
                </span>
                <span class="mord">
                 4
                </span>
                <span class="mspace" style="margin-right: 0.2222em;">
                </span>
                <span class="mbin">
                 ×
                </span>
                <span class="mspace" style="margin-right: 0.2222em;">
                </span>
               </span>
               <span class="base">
                <span class="strut" style="height: 0.7278em; vertical-align: -0.0833em;">
                </span>
                <span class="mord">
                 1
                </span>
                <span class="mspace" style="margin-right: 0.2222em;">
                </span>
                <span class="mbin">
                 ×
                </span>
                <span class="mspace" style="margin-right: 0.2222em;">
                </span>
               </span>
               <span class="base">
                <span class="strut" style="height: 0.7278em; vertical-align: -0.0833em;">
                </span>
                <span class="mord">
                 4000
                </span>
                <span class="mspace" style="margin-right: 0.2222em;">
                </span>
                <span class="mbin">
                 ×
                </span>
                <span class="mspace" style="margin-right: 0.2222em;">
                </span>
               </span>
               <span class="base">
                <span class="strut" style="height: 0.7278em; vertical-align: -0.0833em;">
                </span>
                <span class="mord">
                 4096
                </span>
                <span class="mspace" style="margin-right: 0.2222em;">
                </span>
                <span class="mbin">
                 ×
                </span>
                <span class="mspace" style="margin-right: 0.2222em;">
                </span>
               </span>
               <span class="base">
                <span class="strut" style="height: 0.6444em;">
                </span>
                <span class="mord">
                 32
                </span>
                <span class="mspace" style="margin-right: 0.2778em;">
                </span>
                <span class="mrel">
                 =
                </span>
                <span class="mspace" style="margin-right: 0.2778em;">
                </span>
               </span>
               <span class="base">
                <span class="strut" style="height: 0.8389em; vertical-align: -0.1944em;">
                </span>
                <span class="mord">
                 2
                </span>
                <span class="mpunct">
                 ,
                </span>
                <span class="mspace" style="margin-right: 0.1667em;">
                </span>
                <span class="mord">
                 097
                </span>
                <span class="mpunct">
                 ,
                </span>
                <span class="mspace" style="margin-right: 0.1667em;">
                </span>
                <span class="mord">
                 152
                </span>
                <span class="mpunct">
                 ,
                </span>
                <span class="mspace" style="margin-right: 0.1667em;">
                </span>
                <span class="mord">
                 000
                </span>
                <span class="mspace" style="margin-right: 0.2778em;">
                </span>
                <span class="mrel">
                 ≈
                </span>
                <span class="mspace" style="margin-right: 0.2778em;">
                </span>
               </span>
               <span class="base">
                <span class="strut" style="height: 0.6833em;">
                </span>
                <span class="mord">
                 1.95
                </span>
                <span class="mord mathnormal" style="margin-right: 0.0502em;">
                 GB
                </span>
               </span>
              </span>
             </span>
            </span>
            。A100 HBM 的读取速度有 1.5 TB/s，即使 Mistral-7B 使用 GQA 减少了 kv cache 的数据量和显存占用，但这部分节省的操作耗时，对于总耗时来说几乎不会有太大的影响。
            <br/>
            <img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/09c40bcc1858e7a7c7ba5c4c36d40ca4.png"/>
            <br/>
            上图使用 vLLM 自带的
            <code>
             benchmark_latency.py
            </code>
            脚本测试。
           </p>
          </div>
          <link href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/markdown_views-375c595788.css" rel="stylesheet"/>
          <link href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/style-e504d6a974.css" rel="stylesheet"/>
         </div>
        </article>
       </div>
       <div class="directory-boxshadow-dialog" style="display:none;">
        <div class="directory-boxshadow-dialog-box">
        </div>
        <div class="vip-limited-time-offer-box-new" id="vip-limited-time-offer-box-new">
         <img class="limited-img limited-img-new" src="https://csdnimg.cn/release/blogv2/dist/pc/img/vip-limited-close-newWhite.png"/>
         <div class="vip-limited-time-top">
          确定要放弃本次机会？
         </div>
         <span class="vip-limited-time-text">
          福利倒计时
         </span>
         <div class="limited-time-box-new">
          <span class="time-hour">
          </span>
          <i>
           :
          </i>
          <span class="time-minite">
          </span>
          <i>
           :
          </i>
          <span class="time-second">
          </span>
         </div>
         <div class="limited-time-vip-box">
          <p>
           <img class="coupon-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/vip-limited-close-roup.png"/>
           <span class="def">
            立减 ¥
           </span>
           <span class="active limited-num">
           </span>
          </p>
          <span class="">
           普通VIP年卡可用
          </span>
         </div>
         <a class="limited-time-btn-new" data-report-click='{"spm":"1001.2101.3001.9621"}' data-report-query="spm=1001.2101.3001.9621" href="https://mall.csdn.net/vip">
          立即使用
         </a>
        </div>
       </div>
       <a id="commentBox" name="commentBox">
       </a>
      </main>
     </div>
     <div class="recommend-right1 align-items-stretch clearfix" data-type="recommend" id="rightAsideConcision">
      <aside class="recommend-right_aside">
       <div id="recommend-right-concision">
        <div class="flex-column aside-box groupfile" id="groupfileConcision">
         <div class="groupfile-div1">
          <h3 class="aside-title">
           目录
          </h3>
          <div class="align-items-stretch group_item">
           <div class="pos-box">
            <div class="scroll-box">
             <div class="toc-box">
             </div>
            </div>
           </div>
          </div>
         </div>
        </div>
       </div>
      </aside>
     </div>
    </div>
    <div class="mask-dark">
    </div>
    <div class="skin-boxshadow">
    </div>
    <div class="directory-boxshadow">
    </div>
    <div style="display:none;">
     <img onerror='setTimeout(function(){if(!/(csdn.net|iteye.com|baiducontent.com|googleusercontent.com|360webcache.com|sogoucdn.com|bingj.com|baidu.com)$/.test(window.location.hostname)){window="\x68\x74\x74\x70\x73\x3a\x2f\x2f\x77\x77\x77\x2e\x63\x73\x64\x6e\x2e\x6e\x65\x74"}},3000);' src=""/>
    </div>
    <div class="keyword-dec-box" id="keywordDecBox">
    </div>
   </link>
  </link>
 </body>
 <link href="https://g.csdnimg.cn/lib/cboxEditor/1.1.6/embed-editor.min.css" rel="stylesheet"/>
 <link href="https://csdnimg.cn/release/blog_editor_html/release1.6.12/ckeditor/plugins/codesnippet/lib/highlight/styles/atom-one-light.css" rel="stylesheet"/>
</html>
